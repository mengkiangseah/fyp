%!TEX root = main.tex
\documentclass[main.tex]{subfiles}

\begin{document}
There are a number of areas to evaluate in this project. First, there is the examination of the success of the deliverables. Next, from the wide choice in identification and filtration methods, is the critique of the methods used. The type of testing performed and the analysis of the results offer more insight into the success of the identification and filtration methods. All these are considered in looking possible improvements to this project, and finally, there is a discussion of any other factors to keep in mind.
\\\\
The purpose of this section is to reflect on how well the project's objectives were achieved. As part of that, the ``aims'' in this project were tested as mentioned in Section \ref{sec:goals} and analysed in Section \ref{sec:eval-basic}, but there is also the consideration of the Design Aims that were raised at the start of Chapter \ref{chp:des}. For reference, they are repeated here again.

\begin{enumerate}
	\item Fits into existing setups
	\item Self contained
	\item Functioning without needing input
	\item Not too difficult for a genuine caller to get through
\end{enumerate}

\section{Achievement of Basic Functionality}\label{sec:eval-basic}
Of all the mini-goals attempted, all were successful bar one: the emergency bypass. This was due to the time it took to get the other components. The order of the mini-goals as listed in Section \ref{sec:goals} was in the order that they would be attempted. This was because the philosophy in this project was to prioritise the production of any kind of working implementation, with the core functionality (calling in and out, unhindered) being the first step. This was because the reverse Turing test through the prompt was something that was almost certain to work, and therefore a base implementation would allow for, in the worst-case scenario, a naive method on which to fallback.
\\\\
The main difficulty in the implementation was primarily in combining all the components together. With the help of the hobbyist websites, it was not difficult to configure the Obi110 and the FreePBX, but getting both to work correctly took some experimentation. The original guides were written before updates to the system, which meant that some of the configuration parameters needed to be empirically derived. While Asterisk and FreePBX themselves are no stranger to voice prompts, prerecorded messages and voice recording, having them operate while extracting the audio proved more complicated. Additionally, an interesting challenge was finding a landline on which to test this system. A request to the landlord of a private residence was needed to obtain an active phone number.

\section{Analysis of Testing Methodology}
\subsection{Academic Testing Methods}
The testing of the various methods was based around the three criteria used in the work of Tu et al. \cite{cisco}. This was split into the three categories, usability, robustness, deployability. Under each of those categories, they had 6 criteria, each either completely satisfied, partially satisfied, or not satisfied. They are shown in Table \ref{tbl:methods} \cite{cisco}.

\begin{table}[htb]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Usability} & \textbf{Deployability} & \textbf{Robustness}\\\hline
		Not disturbing the user & Does not need infrastructure changes & Resistant to random Caller IDs\\
		Scalability for the user & No external connections needed & Resistant to impersonating known Caller IDs \\
		Easy for the caller & Low resource requirements & Works without Caller ID\\
		Little delay to the caller & Low maintenance & Resistant to a scammer using multiple lines\\
		Works for VoIP & Low cost & Works against the caller using a machine re-dialer\\
		Works for unknown callers & & Works on varying audio content\\\hline
	\end{tabular}%
	}
	\caption{The different evaluation methods used by Tu et al. \cite{cisco}}
	\label{tbl:methods}
\end{table}

One thing to note in their paper \cite{cisco} is that they made no attempts at implementing any of those proposed methods, and evaluated them theoretically. As such, the Deployability criteria that they use However, not every criteria is relevant to this project, for example the VoIP criteria for Usability. Additionally, the first two Caller ID ones in Robustness are not necessary as the system was designed from the beginning to not incorporate any form of Caller ID, which makes it satisfy the third criteria completely.
\\\\
The use of the criteria system in the three categories is very quantised process, with every method receiving a score in each. This makes it difficult to compare, as there is no obvious way to aggregate the results. Considering each method in the context of each criteria is not productive, as it leads to a normal comparison. However, it offers a clear way to compare the methods employed with those proposed in the paper \cite{cisco}.

\subsection{Implemented Testing Method}
The fact that this project had a physical implementation changed the way it could be assessed as there is a way to display actual performance. That being said, there is a considerable difference in the way this was done. The three categories of evaluation can be turned into three forms of testing. The deployability becomes a discussion of the complexities, the usability is a survey of the experience of callers and users, and the robustness was tested through the use of the metric.
\\\\
There are two downsides to the methods. Testing data was limited in that the call metric was tested using the call transcripts. While this does allow it to be tested at higher speeds, it remains difficult to find call transcripts of spammers. Most people who encounter them are not keen on recording them, and there exists no database to analyse. Setting up a VoIP honeypot as in the work of Marzuoli et al. \cite{marzuoli} could have been done, but the time requirements (over 12 months) and the team and server setup mean that it would have been very challenging. Particularly as the testing phase was done after the research, design, and implementation.

\section{Effectiveness of Identification \& Filtration Methods Used}
\subsection{Analysis of Results}
The test results from the call metric and the survey are considered here. Looking back at Figure \ref{fig:survey}, the results for each question are skewed to the right, suggesting a positive answer to each question. A look at the mean values in Table \ref{tbl:mean} confirms this, as the scores are around 4, with the exception Question 6, which has a lower mean score of 3.5. This means that the display messages are clear, easy to read, and benefit from the colour choice. The Welcome and Goodbye messages are clear understandable but hearing the message discourages people from calling again. This is quite an interesting case as suggests that while a caller is entirely aware of what is going on, the trouble of a keypress or the feeling of dealing with a computer is perhaps a stronger deciding factor.
\\\\
The results of the call metric test in Table \ref{tbl:robust} show very few cases (only 2) of \texttt{LOW} risk calculated. This is correct, as the calls used were all scam calls, and this means an accuracy of $\approx 85\%$ in determining any kind of scam. However, ideally there should be more calls marked \texttt{HIGH}. If the thresholds of each risk level could be visualised, it means that the tolerance for \texttt{LOW} risk is well set. However, the distinction between \texttt{HIGH} and \texttt{MEDIUM} needs to be improved.

\subsection{Comparison with Other Methods}
Given that most of the other methods were evaluated using the criteria from Tu et al. \cite{cisco}, it makes sense to compare this system's combination of a deterrent message, reverse Turing test, weakly secret code, and audio content analysis. This is seen in Table \ref{tbl:compare}. For visibility, the same Table \ref{tbl:methods} is used, with a colour coded system. Red is not satisfied, orange is partially satisfied, and green is fully satisfied.

\begin{table}[htb]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Usability} & \textbf{Deployability} & \textbf{Robustness}\\\hline
		\cellcolor{green!25}Not disturbing the user & \cellcolor{green!25}Does not need infrastructure changes & \cellcolor{green!25}Resistant to random Caller IDs\\
		\cellcolor{green!25}Scalability for the user & \cellcolor{orange!25}No external connections needed & \cellcolor{green!25}Resistant to impersonating known Caller IDs \\
		\cellcolor{orange!25}Easy for the caller & \cellcolor{green!25}Low resource requirements & \cellcolor{green!25}Works without Caller ID\\
		\cellcolor{orange!25}Little delay to the caller & \cellcolor{green!25}Low maintenance & \cellcolor{green!25}Resistant to a scammer using multiple lines\\
		\cellcolor{green!25}Works for VoIP & \cellcolor{orange!25}Low cost & \cellcolor{orange!25}Works against the caller using a machine re-dialer\\
		\cellcolor{green!25}Works for unknown callers & \cellcolor{orange!25}& \cellcolor{green!25}Works on varying audio content\\\hline
	\end{tabular}%
	}
	\caption{The different evaluation methods used by Tu et al. \cite{cisco} applied to this system.}
	\label{tbl:compare}
\end{table}

There are several points to note. First, there are no red cells. This means that it satisfies everything at least on some level. This unlike any of the other methods suggested in the work of Tu et al. \cite{cisco}. However, this is not unexpected, as it is a combination of various methods, all of which were designed not to overlap. In other words, the combination is better than any single method, according to this evaluation strategy.

\subsubsection{Advantages}
The main advantage that this system has over the other methods is the unlike the purely theoretical suggestions, this system was actually implemented. There is good in refining and improving on theory, but if those methods are not made available or possible, then in a practical sense they have lesser value. It is also easy to setup, requiring a connection to the phone and the phone line, apart from power. From the call metric, assuming an most accurate voice transcription, the metric performs decently. Its standalone nature and minimal interaction required make it attractive to those unfamiliar with technology. Additionally, with random keypress generation messages, it is extremely robust against robotic callers.
\\\\
Additionally, as it was designed specifically to not require Caller ID, it means that if it were redesigned to include it, a great deal more options open up, which could improve the identification process further.

\subsubsection{Disadvantages}
In evaluating the model itself, there are two issues. First, from the survey, it is clear that chaining several methods into the system has caused most callers to feel that it takes too long to reach the user. So despite whatever success it may face, the callers are not happy. Removing one or more steps is difficult as each brought its own distinct advantage to the system. The voice analysis brought versatility, while the prompts provided a strong anti-robot call barrier. While Design Aim 4 was to make it less difficult for a genuine caller to get through compared to a fraudulent caller, it seems that overall it is too trouble for legitimate callers.
\\\\
In the call metric, the one downside about the pre-generated lists is that they are limited to the types of calls that they are designed for. Trying to create a dictionary of words that exist in all calls is challenge. And with new types of scam calls appearing all the time, the lists will have trouble recognising the scam calls in vogue. Furthermore, as large companies rise and fall, and current events
\\\\
The system is also always on, just like the phone. However, unlike a phone, which is drawing power from the phone line, this system will consume more power. Even taking into account ways to reduce the size of the setup, with its constant operation, power consumption can be a problem.

\section{Improvements on Implementation and Method}
There are a number of improvements of the implementation and method. This does not include the emergency bypass idea, as it goes without saying that implementing it would be an improvement over not implementing it.

\subsection{Speech Content Analysis}
The first thing is the the original identification method involved recognising the speech in the audio. However, in the implementation, this was done through an online service, the Bing Cloud Speech-to-Text service. This goes directly against Design Aim 2, which is the self-contained goal. The reason for this was that prior experience showed the unreliability of onboard speech processing. Additionally, small devices like the Raspberry Pi 3 have limited computational power compared to larger desktops. As speech recognition can improve with more resources, a realistic aim would be to move to an offline speech recognition platform with a more substantial computing device.

\subsection{Secret Code and Reverse Turing Test}
The secret keypress to bypass the prompt is only a single key. An ideal code would be slightly longer. While this would be more difficult to remember, it does offer the protection against an unknown caller bypassing the voice analysis. While not every unknown caller is dangerous, a dangerous caller that is thought to be safe can be made even more dangerous. And to improve the reverse Turing test, the number to be pressed could benefit from increasing to multiple digits. This must be done carefully to avoid frustrating the caller. It can also be randomised, which does not increase the difficulty for a human caller, but makes it substantially more unlikely for a robotic caller to be configure to handle.

\subsection{Call Start Detection}
The use of the switch was an unfortunate development in the project. The original goal was to have two connections into the system only: the phone line and the phone. However, through the implementation of extracting audio from the Asterisk recording system, some kind of method to detect the start of the call was needed. On the negative side, this does mean an added layer of complexity for the installation process, it is a relatively simple step. A button can be pre-made to be installed directly onto any phone. However, this would still be tricky for cordless phone. In fact, if the system is to work on both a corded and cordless phone, then the idea of using a matched filter to detect the end the ringing cycles is the solution. While this does require more processing power, if a larger computer is used for the speech recognition, then this does not require anything else.

\section{Other Considerations}

\subsection{Data Security and Privacy}
Another reason for the Design Aim of creating a purely self-contained system is because the issue of data privacy is getting bigger and bigger. Transmitting any kind of information to a third-party requires a lot of security to ensure that it cannot be intercepted in transit, and that it cannot be stolen. Not sending anything avoids this problem. However, performing the analysis of the voice means that there is some information stored from the caller. Knowing that recorded calls have a disclaimer at the beginning, it means that keeping anything on a personal device will need to be safe and secure. Even if all data is scrubbed after each call, at the point of analysis, the audio content needs to exist somewhere.

\subsection{User Input}
A lot of user-input based solutions were ignored because it was against Design Aim 3, which was to keep from introducing input, as it makes the system more difficult. However, if considerable care were taken, an input method with absolutely maximum simplicity could be designed, and then the Design Aim 3 would no longer need to be used.

\subsection{Cost}
The overall cost of this system cannot be exorbitant. The trouble with this estimation is that the raw cost of materials in this project is not the average cost, were such a system to be commercialised. There are economies of scale, partnerships, and the cost of development in the prototype as opposed to the cost of labour in a marketable version. This is in contrast to fixed raw material costs, for example, which are not a concern here.

\begin{table}[htb]
	\centering
	\begin{tabular}{|l|r|}
		\hline
		\textbf{Component} 							& \textbf{Price}    								\\\hline
		Raspberry Pi 3 Model B        				& $\pounds 33.96$   								\\
		Transcend 8 GB MicroSD Card 				& $\pounds 25.60$   								\\
		D-Link 5 Port Fast Ethernet Switch 			& $\pounds 15.62$   								\\
		ObiHai Obi110           					& $\pounds 60.00$      								\\
		Handset Button Circuitry    				& $\approx \pounds 1.00$ 							\\\hline
		\multicolumn{1}{|r|}{\textbf{Total}}  & \multicolumn{1}{|l|}{$\pounds 136.18$}  	\\\hline
	\end{tabular}
	\caption{Prices of the various components.}
	\label{tbl:costs}
\end{table}

Looking at the components that made it to the final system, their individual price, and total cost is found in Table \ref{tbl:costs}. Note that the phone is left out, as the system itself is designed fit into existing landline setups. This is quite high compared to other commercially available methods, particularly BT's \textit{BT 8600 Advanced Call Blocker} which retails for $\pounds 59.99$ \cite{bt-block}. This also does not include the price of a monitor, which would have to be included with it.

\subsection{Adaptations for Visibility}
The output of information to the user is purely done visually. This make it difficult for anyone who is visually-impaired to use. This is particularly true for some of the colour schemes, as although the colour choices were designed to emphasis the information, someone colourblind would either not be able to benefit from it, or would have problems reading the text. And the size of the monitor needs to be considered. It must be large enough that reading from it is not impaired, but small enough that it will fit near where the phone installed.

\section{Comparison to Alternatives}
\subsection{Commercially Available}
The commercially available solutions explored in the background in Chapter \ref{chp:bac} mostly revolved around a white and blacklist system. This was quite successful, but as has been mentioned, is not guaranteed on a landline. From the other methods explored, none are currently using voice analysis. In this sense, the comparison is therefore between list-based methods, and voice-analysis based methods.
\\\\
Those methods were not compared previously because they all need some kind of Caller ID, which is not a guarantee on landlines. However, a list-based method is only as good as the lists kept, and with the constantly changing nature of the scammers, this means it needs constant updates. And because the list only adds a known scammer onto the blacklist, then every scammer will get through at least once to someone somewhere.
\\\\
There is the possibility of having individual lists that are maintained by the user, but this requires their involvement, which may not always be desirable. If the lists are managed by a company, then the services offered are subscription based, meaning they present a constant cost.

\subsection{Non-technical Approach}
The main purpose of this system is to reduce the encounter rate of nuisance and fraudulent calls. In the case of the later, the goal is to either reduce the rate of encountering calls, or to warn the user of such a call. However, a non-technical approach should also be considered. By reaching out and informing users of the dangers of scam calls, and how to recognise them, then the financial risk is lessened.

\subsection{Telephone Service Providers}
While techniques from the academic side of the background research yielded several methods for use on communication infrastructures, there is no discussion of whether phone companies actively monitor their lines for illegitimate use. If a known number from somewhere in the country is constantly sending out spam calls, a phone company might consider taking action. While the scammers are no doubt using multiple numbers, temporary numbers, or VoIP numbers, there is also the legal considerations of denying or monitoring calls.

\end{document}
